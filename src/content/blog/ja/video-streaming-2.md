---
title: 'ブラウザでHEVC映像をストリーミングする #2'
description: 'RTSPと共に踊る'
pubDate: 'May 06 2025'
heroImage: '../../../assets/images/streaming.jpg'
category: 'Frontend'
tags: ['video']
lang: 'ja'
---

## Overview

RTSPパケットを解析してビデオとオーディオ、そしてメタデータを抽出する必要があります。そして、それをブラウザに**注意深く**送信する必要があります。

## RTSP

この記事を読んでいるということは、[この文書](https://www.rfc-editor.org/rfc/rfc2326.html)を読んだということです。したがって、RTSPに関する説明は省略し、あなたは既にRTSPに精通していると仮定します。また、あなたはNaver Cloud技術ブログとTwitch技術ブログ、そしてStackOverflowやRedditでウェブビデオストリーミングに必要なサーバー構成図と映像情報がどこから始まってどこに流れるかについて、退勤後毎日数時間ずつ調査し、また直接作成したことがあるでしょう。関連内容は省略します。

私たちはWebRTCを使用しないため（私たちが再生する映像のコーデックがブラウザがサポートしないコーデックであるため、RTPパケットを直接制御する必要がありますが、ブラウザのポリシー上RTP直接制御はできず、High level APIのみを提供します）、RTSPパケットから映像を直接抽出する必要があります。

映像抽出はRTSPに精通したあなたにとって問題にならないでしょう。しかし、それをブラウザに送信する際に考慮すべき点があります。

## 余談：AVCCとAnnexBはコンテナフォーマットである（オープンソース貢献）

使用しているRTSPクライアントオープンソースライブラリが断続的にIFrameが10秒間入ってこなかったとしてセッションを終了する現象が継続的に発生し、プロダクション環境でも再現されました（該当カメラは30 IPSでした）。Githubで該当オープンソースライブラリのイシューを調べていると、私たちの状況と思われるイシューが既に存在しており、誰もそれを修正していませんでした。

原因は、RTP ClientがRTPパケットを受信するとすぐにAVCC、AnnexBの解析を行っていたためです。ご存知のように、AVCCとAnnexBはコンテナフォーマットであり、RTP Payloadには単にNALuがpacketization modeに従って1個または複数個入っているだけです。当然、Emulation Preventionがないため、AVCC検証が失敗した場合、Single NALuが複数のデータ片に分割され、IFrame検証ロジックで誤ったビットを検査した後、IFrameが入ってこないという例外を発生させます。

さらに、Packetization Modeをすべて実装していませんでした！偶然、私たちのRTPサーバーが該当RTSPクライアントが解析可能なPacketization Modeでパケットを送信しただけでした。

その2つの問題をすべて修正してプルリクエストを提出しました。以前にも同一ライブラリのバグ修正のためにプルリクエストを提出し、その時はメンテナーが私が作成したプルリクエストを確認するのに約1年かかりましたが、果たして今回はどうでしょうか。

ウェブ開発者は首をかしげるでしょうが、ウェブエコシステムが異常なほどオープンソースに活気に満ちているのは、元々このようなものです...

## プロトコル選択

ブラウザがサポートするプロトコルのうち、どれで映像を送信するか決定する必要があります。

1. HTTP/1とHTTP/2
2. WebSocket
3. HTTP/3

バックプレッシャー（ブラウザ側でデコーディングを行った後、映像がメモリをかなり消費します。ビデオ圧縮方式の効率が非常に良いためです）は絶対に必要です。バックプレッシャーがないと、ブラウザメモリがクラッシュします。したがって、TCP window sizeを動的に調整できる2番と3番に絞られます。

ここでの核心は、供給速度をクライアント側で制御する方法が必要だということです。それが上記で説明したTCP window sizeを減らす方式であれ、私が考えもしなかった他の方式であれ、いずれにせよ、あなたは悩んだ末に2番と3番のいずれかを選択することになります。私は知っています。

## RTSPとWebSocket/WebTransportは別々に考える必要がある。単にリレーするだけではいけない。

TCP window sizeを減らしてしまう状況がかなり頻繁に発生します。その時、あなたが単にリレーするだけのサーバーを作成したとします。後でブラウザがメモリが余ってTCP window sizeを再び上げるまで、かなり長い時間がかかり、RTSPは既に切断されているでしょう（VODで映像が終了した場合）。そして、あなたが実装したサーバーはリレーするだけなので、RTSPが切断されたときにWebSocket/WebTransportが切断されます。すると、ブラウザの立場では、せっかくメモリに余裕ができたのに、再生するものがもうなくなってしまうことになります。

そのような状況を防ぐために、ストリーミングに関わるサーバーのうち、MediaサーバーがOnDemandである場合、あなたはイベント駆動アーキテクチャで実装する必要があります。

メディアサーバーをすべて作成したなら、今度はプレイヤーの時間です。
次編に続く
