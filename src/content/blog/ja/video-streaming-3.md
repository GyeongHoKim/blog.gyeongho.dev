---
title: 'ブラウザでHEVC映像をストリーミングする #3'
description: 'RTPサーバーとメディアサーバーとブラウザそして私'
pubDate: 'May 07 2025'
heroImage: '../../../assets/images/streaming.jpg'
category: 'Frontend'
tags: ['video']
lang: 'ja'
---

## Overview

詳細な内容は省略しますが、ウェブでの映像再生について深く考察したことがあれば、以下の内容を見て大部分を理解できるでしょう。

## 再生の主体、そしてLiveとVOD

再生の主体がブラウザでなければ、実際にはLiveとVODに区別はありません。両方ともLive映像として処理すればよいです。  
問題は、再生の主体がブラウザである場合に発生します。

## ウェブアセンブリ

ブラウザが解釈できないHEVC映像を表示する必要があるため、HEVCデコーディングを直接実装する必要があります。
私の場合は、AVCとHEVCの両方をサポートするようにウェブアセンブリを作成しました。

FFmpegにSIMDサポートを提供しないのかという話は以前からあり、これを行うにはウェブフロントエンドとビデオデコーディングの両方の分野で働いたことがある人がFFmpegプロジェクトを主導する必要がありますが、まずそこから現実性がありません。残念ながら、ウェブフロントエンド開発者の大部分はビデオデコーディングに興味がなく、FFmpegメンテナーはウェブに興味がありません。

FFmpegのイシュー回答を見ると、不要だからしないという回答があります。彼らはそもそもウェブに興味がありません。
中国の開発者が非常にイライラしたため、DCTのみSIMDサポートしたものがあるので、それを使用してみてもよいです。

https://www.nxrte.com/jishu/53948.html を参照してください。

## バックプレッシャー

2編で説明したように、ブラウザ側でサーバーの映像供給速度を制御する必要があります。簡単です。CPUとメモリの状態をモニタリングし、TCP window sizeを適切に減らせばよいです。メモリ状態の場合、performance.memoryが非標準であるため使用しにくいかもしれませんが、その場合は単にhigh water markを希望のバイト単位で指定して使用するのも悪くありません。私の場合は、CPUはnominalの場合のみ、メモリは、high water markで適切なバイト容量を計算して（sizeコールバックでバイトを計算する方式を入れないと、chunk全体でサイズが取られるため注意が必要です）、ブロッキング処理を行いました。

メディアサーバーがイベント駆動アーキテクチャでないか、RTSP Life CycleとWebSocket/WebTransport Life Cycleを一致させるように実装した場合、この部分で問題が発生する可能性があるため、注意が必要です。

## WebCodecs API

大部分のブラウザAPIはエンコードされた映像を基準としています。Raw Videoを使用したい場合は、WebCodecsのVideoFrameを活用する必要があります。デコードされた映像は通常YUV Planeに定義されますが、このバッファをVideoFrameに変換すればよいです。WebCodecs APIはraw video基準であるため、これを使用する必要があります。

**注意**：RTPタイムスタンプはメディアごとに単位が異なるため、SDPを解析してClock Rateを確認し、マイクロ秒単位に変換する必要があります。相対値であるため、最初のフレームを見て時間差で記録すればよいです。

## JSONにunsigned int 64を入れると情報が損失される

JSON解析はデフォルトでnumberに変換しますが、これはdoubleに該当するため、unsigned int 64を入れると情報が損失されます。
映像ではタイムスタンプがかなり重要であるため、unsigned int 64を入れるのではなく、Bufferとして入れてDataViewで解析するか、または受信時にStreamとして受信してBigIntで解析する必要があります。

## マルチプロセス

映像を受信する側、そしてレンダリングする側はI/Oが頻繁で、デコーディングはCPU集約的です。したがって、ウェブワーカーを使用する必要があります。

## モニターリフレッシュレート

フレームドロップは悪いことではありません！すべてのフレームを再生すると、再生速度が合わなくなります。モニターリフレッシュレートに合わせて適切にフレームドロップを実行してください。

## レンダリングはGPUで

WebGPUは今や標準です。wgsl言語を学び、GPUでレンダリングしましょう。やってみると分かりますが、最もリソースを消費するのはデコーディングではありません。レンダリングです。

## Video elementを活用する方法

Video elementが受信するsource bufferはraw videoをサポートしません。したがって、TrackのwritableにVideoFrameを直接書き込む必要があります。

試してみましたが、結局Canvasに戻ることになります。そもそもVideo elementを使用する理由は、HTML5のVideo elementが提供するコールバックとAPIを使用するためですが、私たちはメモリ管理を直接行い、再生の主体がブラウザにあるため、直接制御する部分が増えれば増えるほど、使用できないAPIが次第に増えていきます。
